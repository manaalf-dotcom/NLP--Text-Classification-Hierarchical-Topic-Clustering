# -*- coding: utf-8 -*-
"""Text Classification & Hierarchical Topic Clustering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9NF6fWuXSG5jquvqsllOvgEtdFkJOX_
"""



#scikit-learn 20 Newsgroups
def load_default_dataset():
    from sklearn.datasets import fetch_20newsgroups

    data = fetch_20newsgroups(subset="all", categories=None, remove=("headers","footers","quotes"))

    X_text = data.data
    y = data.target
    label_names = data.target_names

    df = pd.DataFrame({"text": X_text, "label": y})
    return df, label_names

df, label_names = load_default_dataset()

print("Dataset loaded.")
print("Rows:", len(df))
print("Labels:", label_names)
print("\nLabel distribution:")
print(df["label"].value_counts(normalize=True).rename("share"))

print("\nSample rows:")
df.head(3)

#Split the data, 80% for training and 20% for testing
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df["text"], df["label"],
    test_size=0.2,
    random_state=42,
    stratify=df["label"]  # ensures all 20 classes are balanced in both splits
)

print("Train size:", len(X_train))
print("Test size:", len(X_test))

"""Vectorization and Models"""

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix

# Define all 4 pipelines
pipelines = {
    "Naive Bayes":         Pipeline([("tfidf", TfidfVectorizer(max_features=50000, min_df=2)), ("clf", MultinomialNB())]),
    "Logistic Regression": Pipeline([("tfidf", TfidfVectorizer(max_features=50000, min_df=2)), ("clf", LogisticRegression(max_iter=1000))]),
    "Linear SVM":          Pipeline([("tfidf", TfidfVectorizer(max_features=50000, min_df=2)), ("clf", LinearSVC())]),
    "Random Forest":       Pipeline([("tfidf", TfidfVectorizer(max_features=10000, min_df=2)), ("clf", RandomForestClassifier(n_estimators=100))]),
}

# Train and evaluate each one
results = []
for name, pipeline in pipelines.items():
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    f1  = f1_score(y_test, y_pred, average="macro")

    print(f"\n{name}")
    print(f"  Accuracy: {acc:.4f} | Macro F1: {f1:.4f}")

    results.append({"Model": name, "Accuracy": round(acc,4), "Macro F1": round(f1,4)})

# Summary table
import pandas as pd
results_df = pd.DataFrame(results).sort_values("Macro F1", ascending=False)
print("\n", results_df)

import matplotlib.pyplot as plt
import numpy as np

models = results_df["Model"]
x = np.arange(len(models))
width = 0.35

fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(x - width/2, results_df["Accuracy"], width, label="Accuracy", color="steelblue")
ax.bar(x + width/2, results_df["Macro F1"], width, label="Macro F1", color="coral")

ax.set_xticks(x)
ax.set_xticklabels(models, rotation=15)
ax.set_ylim(0, 1)
ax.set_title("Part 1 ‚Äî Model Comparison (TF-IDF)")
ax.set_ylabel("Score")
ax.legend()
plt.tight_layout()
plt.show()

"""Based on the test, the best model is Linear SVM"""

from sklearn.metrics import ConfusionMatrixDisplay

best_pipeline = pipelines["Linear SVM"]
y_pred_best = best_pipeline.predict(X_test)

cm = confusion_matrix(y_test, y_pred_best)

fig, ax = plt.subplots(figsize=(14, 12))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)
disp.plot(ax=ax, xticks_rotation=90, colorbar=True, cmap="Blues")
ax.set_title("Confusion Matrix ‚Äî Linear SVM")
plt.tight_layout()
plt.show()

import pandas as pd

confusion_pairs = []
for i in range(len(label_names)):
    for j in range(len(label_names)):
        if i != j and cm[i][j] > 0:
            confusion_pairs.append({
                "True Label": label_names[i],
                "Predicted As": label_names[j],
                "Count": cm[i][j]
            })

pairs_df = pd.DataFrame(confusion_pairs).sort_values("Count", ascending=False).head(10)
print("Top 10 Confusion Pairs:\n")
print(pairs_df.to_string(index=False))

pairs_df_top = pairs_df.head(10).copy()
pairs_df_top["Pair"] = pairs_df_top["True Label"] + "\n‚Üí " + pairs_df_top["Predicted As"]

plt.figure(figsize=(12, 6))
plt.barh(pairs_df_top["Pair"], pairs_df_top["Count"], color="coral")
plt.xlabel("Number of Misclassifications")
plt.title("Top 10 Confusion Pairs ‚Äî Linear SVM")
plt.gca().invert_yaxis()  # highest count on top
plt.tight_layout()
plt.show()

"""PART TWO"""

!pip install sentence-transformers

from sentence_transformers import SentenceTransformer

# Load the pre-trained model
model = SentenceTransformer('all-MiniLM-L6-v2')

print("Encoding training data...")
X_train_emb = model.encode(X_train.tolist(), show_progress_bar=True, batch_size=64)

print("Encoding test data...")
X_test_emb = model.encode(X_test.tolist(), show_progress_bar=True, batch_size=64)

print("Train embeddings shape:", X_train_emb.shape)
print("Test embeddings shape:", X_test_emb.shape)

classifiers = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Linear SVM":          LinearSVC(),
    "Random Forest":       RandomForestClassifier(n_estimators=100, random_state=42),
}

results_part2 = []

for name, clf in classifiers.items():
    clf.fit(X_train_emb, y_train)
    y_pred = clf.predict(X_test_emb)

    acc = accuracy_score(y_test, y_pred)
    f1  = f1_score(y_test, y_pred, average="macro")

    print(f"\n{name}")
    print(f"  Accuracy: {acc:.4f} | Macro F1: {f1:.4f}")

    results_part2.append({"Model": name, "Accuracy": round(acc,4), "Macro F1": round(f1,4)})

"""Running Naive Bayes seperately as numbers have to be positive"""

from sklearn.preprocessing import MinMaxScaler

# Scale embeddings to be all positive (0 to 1) so NB can handle them
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train_emb)
X_test_scaled  = scaler.transform(X_test_emb)

nb_clf = MultinomialNB()
nb_clf.fit(X_train_scaled, y_train)
nb_pred = nb_clf.predict(X_test_scaled)

acc_nb = accuracy_score(y_test, nb_pred)
f1_nb  = f1_score(y_test, nb_pred, average="macro")

print(f"\nNaive Bayes (scaled embeddings)")
print(f"  Accuracy: {acc_nb:.4f} | Macro F1: {f1_nb:.4f}")

results_part2.append({"Model": "Naive Bayes", "Accuracy": round(acc_nb,4), "Macro F1": round(f1_nb,4)})

# Results table
results_p2_df = pd.DataFrame(results_part2).sort_values("Macro F1", ascending=False)
print("\nPart 2 Results:")
print(results_p2_df)

# Side by side comparison chart ‚Äî Part 1 vs Part 2
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Part 1 chart
axes[0].bar(results_df["Model"], results_df["Macro F1"], color="steelblue")
axes[0].set_title("Part 1 ‚Äî TF-IDF Macro F1")
axes[0].set_ylim(0, 1)
axes[0].set_xticklabels(results_df["Model"], rotation=15)
axes[0].set_ylabel("Macro F1")

# Part 2 chart
axes[1].bar(results_p2_df["Model"], results_p2_df["Macro F1"], color="coral")
axes[1].set_title("Part 2 ‚Äî SentenceTransformer Macro F1")
axes[1].set_ylim(0, 1)
axes[1].set_xticklabels(results_p2_df["Model"], rotation=15)
axes[1].set_ylabel("Macro F1")

plt.tight_layout()
plt.show()

"""PART THREE"""

from google import genai

# Initialize the new client
client = genai.Client(api_key="")

#test api
response = client.models.generate_content(
    model="gemini-2.5-flash-lite",
    contents="Say hello in one word"
)

print(response.text)

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

wcss = []
k_range = range(2, 12)

for k in k_range:
    km = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)
    km.fit(X_train_emb)
    wcss.append(km.inertia_)
    print(f"K={k} done")

plt.figure(figsize=(8, 5))
plt.plot(k_range, wcss, marker='o', color='steelblue')
plt.title("Elbow Method ‚Äî Finding Best K")
plt.xlabel("Number of Clusters (K)")
plt.ylabel("WCSS (Inertia)")
plt.xticks(k_range)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd

K = 6

kmeans = KMeans(n_clusters=K, init='k-means++', random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(X_train_emb)

# See how many documents are in each cluster
cluster_sizes = pd.Series(cluster_labels).value_counts().sort_index()
print("Documents per cluster:")
print(cluster_sizes)

def get_cluster_label(docs):
    doc_text = "\n\n".join([f"Document {i+1}: {doc[:150]}" for i, doc in enumerate(docs)])

    prompt = f"""Here are 5 news articles from the same topic cluster.
Respond with ONLY a short 2-4 word topic label.
Do not explain, just give the label.

{doc_text}

Topic label:"""

    response = client.models.generate_content(
        model="gemini-2.5-flash-lite",  # updated model
        contents=prompt
    )
    return response.text.strip()

import time

cluster_labels_text = {}
for cluster_id in range(K):
    docs = [X_train.iloc[idx] for idx in indices[cluster_id]]
    label = get_cluster_label(docs)
    cluster_labels_text[cluster_id] = label
    print(f"Cluster {cluster_id} ({cluster_sizes[cluster_id]} docs): {label}")
    time.sleep(10)  # wait 10 seconds between calls

print("\nAll clusters labeled!")
print(cluster_labels_text)

# Check what's in cluster 2
member_indices_2 = np.where(cluster_labels == 2)[0]
print(f"Cluster 2 has {len(member_indices_2)} documents")
print("\nSample documents:")
for idx in member_indices_2[:5]:
    print("---")
    print(X_train.iloc[idx][:300])

# Manually assign label for cluster 2
cluster_labels_text[2] = "Empty/Noise Documents"

# Verify all labels now
for cluster_id in range(K):
    print(f"Cluster {cluster_id} ({cluster_sizes[cluster_id]} docs): {cluster_labels_text[cluster_id]}")

import numpy as np

# Confirm the 2 biggest clusters
top2_clusters = cluster_sizes.nlargest(2).index.tolist()
print("2 biggest clusters:", top2_clusters)
print(f"Cluster {top2_clusters[0]}: {cluster_labels_text[top2_clusters[0]]}")
print(f"Cluster {top2_clusters[1]}: {cluster_labels_text[top2_clusters[1]]}")

sub_cluster_labels = {}

for parent_cluster in top2_clusters:
    print(f"\nSub-clustering Cluster {parent_cluster} ({cluster_labels_text[parent_cluster]})...")

    # Get all documents belonging to this cluster
    member_indices = np.where(cluster_labels == parent_cluster)[0]
    member_embeddings = X_train_emb[member_indices]

    # Re-cluster into exactly 3 sub-clusters
    sub_km = KMeans(n_clusters=3, init='k-means++', random_state=42, n_init=10)
    sub_labels = sub_km.fit_predict(member_embeddings)

    # Find 5 representative docs per sub-cluster
    sub_centroids = sub_km.cluster_centers_
    sub_nbrs = NearestNeighbors(n_neighbors=5, algorithm='brute', metric='cosine')
    sub_nbrs.fit(member_embeddings)
    _, sub_indices = sub_nbrs.kneighbors(sub_centroids)

    # Label each sub-cluster with Gemini
    sub_cluster_labels[parent_cluster] = {}
    for sub_id in range(3):
        sub_docs = [X_train.iloc[member_indices[idx]] for idx in sub_indices[sub_id]]
        sub_label = get_cluster_label(sub_docs)
        sub_cluster_labels[parent_cluster][sub_id] = sub_label
        print(f"  Sub-cluster {sub_id}: {sub_label}")
        time.sleep(10)  # avoid rate limit

print("\nDone!")
print(sub_cluster_labels)

print("\n" + "="*50)
print("           TOPIC TREE")
print("="*50)

for cluster_id in range(K):
    label = cluster_labels_text[cluster_id]
    size = cluster_sizes[cluster_id]

    if cluster_id in top2_clusters:
        # Show with sub-clusters
        print(f"\nüìÅ Cluster {cluster_id}: {label}  ({size} docs)")
        for sub_id, sub_label in sub_cluster_labels[cluster_id].items():
            if sub_id == 2:
                print(f"    ‚îî‚îÄ‚îÄ {sub_label}")
            else:
                print(f"    ‚îú‚îÄ‚îÄ {sub_label}")
    else:
        # Show as leaf node
        print(f"\nüìÑ Cluster {cluster_id}: {label}  ({size} docs)")

print("\n" + "="*50)